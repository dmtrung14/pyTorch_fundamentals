{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlch3wjZ421K1c0I0QP2ql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmtrung14/pyTorch_fundamentals/blob/main/PyTorch_Fundamentals_Classification_Problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch in Machine Learning Classification"
      ],
      "metadata": {
        "id": "xrulyc2r-Qfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of classification problems: \n",
        "* Binary classification: Spam filtering\n",
        "* Multiclass: food identifier\n",
        "* Multilabel classification: what tags should this wikipedia have?\n",
        "\n",
        "Let's not mistaken *Multiclass* vs *multilabel* classification, the first one define which class among the labels should this object be classified as, and the later one which (multiple labels) should be applied. \n",
        "\n",
        "As we'll see, we will use `softmax` for the first one, and other algos for the latter\n"
      ],
      "metadata": {
        "id": "nBJOmzrkIfIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make classificaion data and get it ready"
      ],
      "metadata": {
        "id": "lKe627EU-OsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "HkrVnw3sPwSV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "#Make 1000 samples\n",
        "n_samples = 1000\n",
        "\n",
        "x,y = make_circles(n_samples, noise = 0.03, random_state= 42)\n",
        "\n",
        "len(x), len(y), x[:5], y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q-cdZZLPzOI",
        "outputId": "df5b6c27-8baf-4647-c4cb-454ef73e9eb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,\n",
              " 1000,\n",
              " array([[ 0.75424625,  0.23148074],\n",
              "        [-0.75615888,  0.15325888],\n",
              "        [-0.81539193,  0.17328203],\n",
              "        [-0.39373073,  0.69288277],\n",
              "        [ 0.44220765, -0.89672343]]),\n",
              " array([1, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.lib.display import YouTubeVideo\n",
        "# Make DataFram of circle data\n",
        "import pandas as pd\n",
        "circles = pd.DataFrame({\"X1\": x[:,0], \n",
        "                        \"X2\": x[:,1],\n",
        "                        \"label\": y})\n",
        "circles.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WG0J51gfQN9y",
        "outputId": "64fbfab2-b582-4658-b85c-8120c6e52053"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         X1        X2  label\n",
              "0  0.754246  0.231481      1\n",
              "1 -0.756159  0.153259      1\n",
              "2 -0.815392  0.173282      1\n",
              "3 -0.393731  0.692883      1\n",
              "4  0.442208 -0.896723      0\n",
              "5 -0.479646  0.676435      1\n",
              "6 -0.013648  0.803349      1\n",
              "7  0.771513  0.147760      1\n",
              "8 -0.169322 -0.793456      1\n",
              "9 -0.121486  1.021509      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d4bbf3c-a0d3-47a9-af86-d8b6d316e712\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.754246</td>\n",
              "      <td>0.231481</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.756159</td>\n",
              "      <td>0.153259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.815392</td>\n",
              "      <td>0.173282</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.393731</td>\n",
              "      <td>0.692883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.442208</td>\n",
              "      <td>-0.896723</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.479646</td>\n",
              "      <td>0.676435</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.013648</td>\n",
              "      <td>0.803349</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.771513</td>\n",
              "      <td>0.147760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.169322</td>\n",
              "      <td>-0.793456</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.121486</td>\n",
              "      <td>1.021509</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d4bbf3c-a0d3-47a9-af86-d8b6d316e712')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d4bbf3c-a0d3-47a9-af86-d8b6d316e712 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d4bbf3c-a0d3-47a9-af86-d8b6d316e712');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check input and output shapes\n"
      ],
      "metadata": {
        "id": "kh_EZoZATBeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTugoyPxTFAX",
        "outputId": "a72381d4-6e1c-44de-ead1-8c4b25456f64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 2), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn data into tensors and create train and test splits"
      ],
      "metadata": {
        "id": "JKn9S4RaTUTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "iesJovdMTYvB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.from_numpy(x).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)"
      ],
      "metadata": {
        "id": "gy3p8sa_TdeN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state = 42)\n",
        "len(x_train), len(x_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK8ysfX-TwDa",
        "outputId": "7fa104b8-82b4-416c-e441-8cac54c9260c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 200, 800, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a model\n",
        "\n",
        "Let's build a model to classify our points into 2 circles. \n",
        "To do so, we want to:\n",
        "1. set up device agnostic code so our code will run on an acceleartor (GPU) if there is one.\n",
        "2. Construct a model (by subclassing `nn.Module`)\n",
        "3. Define a loss function and an optimizer\n",
        "4. Create a training and test loop\n"
      ],
      "metadata": {
        "id": "6_DNkl1JUqFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "## Make device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WQxCj5ZWVBsz",
        "outputId": "317c6e23-18e7-4d23-9b36-da4aa2e47a31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've setup device agnostic code, let's create a model that:\n",
        "\n",
        "1. Subclass ``nn.module`` (almost all models in PyTOrch subclass this module)\n",
        "2. Create 2 `nn.Linear` layers that are capable of handling the shapes of our data\n",
        "3. Define a `forward()` method that outlines the forward pass for forward computation of the model\n",
        "4. Instantiate an instance of our model class and send it to the target device.\n"
      ],
      "metadata": {
        "id": "MRnKvgn3VhIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a model that subclasses nn.Module\n",
        "\n",
        "class CircleModelV0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features = 2, out_features =5) #Takes in 2 features and output 5 features\n",
        "    self.layer_2 = nn.Linear(in_features = 5, out_features = 1) #Takes in 5 features and output 1 result\n",
        "  \n",
        "  #Define a forward() method that outlines the forward pass\n",
        "  def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "    return self.layer_2(self.layer_1(x)) #x -> layer 1 -> layer 2 -> output\n",
        "\n",
        "# Instantiate an instance of our model class and send it to the target device\n",
        "\n",
        "model_0 = CircleModelV0().to(device)\n",
        "list(model_0.parameters())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpmj7yxxV0WQ",
        "outputId": "f98a18cf-8755-4cdb-ebe2-fe45becbb01a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.2558, -0.2993],\n",
              "         [-0.6544, -0.4216],\n",
              "         [ 0.5142,  0.4256],\n",
              "         [ 0.6886,  0.6829],\n",
              "         [-0.1417,  0.0173]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.5412,  0.0892, -0.0575,  0.1808, -0.5940], device='cuda:0',\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0765,  0.1801,  0.0993,  0.0444,  0.0437]], device='cuda:0',\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1903], device='cuda:0', requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "NyKr5SVvV69t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a2e93549-55ed-4f32-f0ec-2b366f20ffac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##``nn.Sequential`` to replicate the model in an easier ưay\n",
        "\n"
      ],
      "metadata": {
        "id": "gLj_xUOAYca8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = nn.Sequential(\n",
        "    nn.Linear(in_features = 2, out_features = 5),\n",
        "    nn.Linear(in_features = 5, out_features = 1)\n",
        ").to(device)\n",
        "\n",
        "model_0, model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edNsjNlJYjdB",
        "outputId": "86ab472c-2d3d-4a19-dc08-df17db05e5f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Sequential(\n",
              "   (0): Linear(in_features=2, out_features=5, bias=True)\n",
              "   (1): Linear(in_features=5, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('0.weight',\n",
              "               tensor([[-0.1123, -0.4245],\n",
              "                       [-0.3988,  0.1052],\n",
              "                       [ 0.5334,  0.3251],\n",
              "                       [ 0.3103, -0.4958],\n",
              "                       [ 0.0657,  0.2498]], device='cuda:0')),\n",
              "              ('0.bias',\n",
              "               tensor([ 0.0723,  0.6632, -0.5456,  0.0171,  0.6458], device='cuda:0')),\n",
              "              ('1.weight',\n",
              "               tensor([[ 0.0251, -0.2089,  0.1239, -0.0135, -0.3588]], device='cuda:0')),\n",
              "              ('1.bias', tensor([0.3209], device='cuda:0'))]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's make some prediction with our new model:\n",
        "untrained_preds = model_0(x_test.to(device))\n",
        "x_test[:10], untrained_preds[:10], torch.round(untrained_preds[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpwjd_dMZb74",
        "outputId": "fbbc3cd2-6ade-4c14-c0d0-9b4361a32866"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.3752,  0.6827],\n",
              "         [ 0.0154,  0.9600],\n",
              "         [-0.7028, -0.3147],\n",
              "         [-0.2853,  0.9664],\n",
              "         [ 0.4024, -0.7438],\n",
              "         [ 0.6323, -0.5711],\n",
              "         [ 0.8561,  0.5499],\n",
              "         [ 1.0034,  0.1903],\n",
              "         [-0.7489, -0.2951],\n",
              "         [ 0.0538,  0.9739]]),\n",
              " tensor([[-0.2114],\n",
              "         [-0.1859],\n",
              "         [-0.1753],\n",
              "         [-0.2221],\n",
              "         [-0.0116],\n",
              "         [ 0.0027],\n",
              "         [-0.0551],\n",
              "         [-0.0105],\n",
              "         [-0.1822],\n",
              "         [-0.1824]], device='cuda:0', grad_fn=<SliceBackward0>),\n",
              " tensor([[-0.],\n",
              "         [-0.],\n",
              "         [-0.],\n",
              "         [-0.],\n",
              "         [-0.],\n",
              "         [0.],\n",
              "         [-0.],\n",
              "         [-0.],\n",
              "         [-0.],\n",
              "         [-0.]], device='cuda:0', grad_fn=<RoundBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up loss function and optimizer\n",
        "Which loss function or optimizer should you use?\n",
        "\n",
        "For example, for regression you might want MAE or MSE\n",
        "\n",
        "For classification you might want binary cross entropy or categorical cross entropy\n",
        "\n",
        "* For the loss function we are going to use ``torch.nn.BCEWithLogitsLoss()``."
      ],
      "metadata": {
        "id": "8OZ5sS3Iayj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "s3IwZXtrb0g3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate accuracy - out of 100 example, what percentage does our model get right?\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred))*100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "qrnL6SVfcY2G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train our Model\n",
        "\n",
        "To train our model, we need to build a training loop, which includes:\n",
        "\n",
        "1. Forward pass\n",
        "2. Calculate the loss\n",
        "3. Optimizer zero gra\n",
        "4. Loss backward (backpropagation)\n",
        "5. Optimizer step (gradient descent)"
      ],
      "metadata": {
        "id": "ZfS-H4bTRe-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Going from raw logits -> prediction probabilities -> prediction labels\n",
        "\n",
        "Our model outpus are going to be raw logits\n"
      ],
      "metadata": {
        "id": "2bcoeCHkTK8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert these logits into prediction probabilityies by passing them to some kind of activation function (e.g. sigmoid for binary classification and softwmax for mutlticlass classification)\n",
        "\n",
        "Then we can convert our model's prediction probabilities to **prediction labels** by either rounding them or taking the `argmax()`"
      ],
      "metadata": {
        "id": "_GEnOBNnTTdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view the first 5 outputs of the forward pass on the test data\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_logits = model_0(x_test.to(device))[:5]\n",
        "y_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtwD6jJNTot5",
        "outputId": "a8e3e2dd-b3df-4282-c549-cb448ed58ccf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2114],\n",
              "        [-0.1859],\n",
              "        [-0.1753],\n",
              "        [-0.2221],\n",
              "        [-0.0116]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the sigmoid activation function on our model logits to turn them into prediction\n",
        "y_pred_probs = torch.sigmoid(y_logits)\n",
        "y_pred_probs, torch.round(y_pred_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4poED1TixWDA",
        "outputId": "d22b231a-095c-4aae-ef33-fa7825a33943"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.4473],\n",
              "         [0.4537],\n",
              "         [0.4563],\n",
              "         [0.4447],\n",
              "         [0.4971]], device='cuda:0'),\n",
              " tensor([[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our prediction probability values, we need to perform a range-style rounding on them:\n",
        "* `y_pred_probs` >= 0.5, `y =1`, (class 1)\n",
        "* `y_pred_probs` < 0.5, `y = 0`, (class 0)\n"
      ],
      "metadata": {
        "id": "dG0R_JYQx014"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the predicted labels\n",
        "y_preds = torch.round(y_pred_probs)\n",
        "\n",
        "#In full\n",
        "y_pred_labels = torch.round(torch.sigmoid(model_0(x_test.to(device))[:5]))\n",
        "\n",
        "#Check for equality\n",
        "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
        "\n",
        "y_preds.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxq092qfyEGA",
        "outputId": "6fe61757-bcc0-4ea9-e86b-7a122ce009d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgBbQOA3yuCG",
        "outputId": "bbb6c5ef-f828-44c8-99a6-85d0175d641a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 1., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Building a training and testing loop of our own\n"
      ],
      "metadata": {
        "id": "QMQv5d_sywPw"
      }
    }
  ]
}